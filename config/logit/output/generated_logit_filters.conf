filter {
  mutate {
    add_field => [ "type", "syslog" ]
  }

  #
  # rewrite our defined globals
  #

  if [type] == 'redis' or [type] == 'redis-input' {
      mutate {
          remove_field => [ 'type' ]
      }
  }

  if [type] != '' {
      mutate {
          rename => [ "type", "@type" ]
      }
  }

  if [message] != '' {
      mutate {
          rename => [ "message", "@message" ]
      }
  } else if [message] == '' and [@message] !~ /^.+$/ {
      drop { }
  }

  #
  # avoid bad interpolations, like `%{type}` when its missing
  #

  if [@type] == "" {
      mutate {
          add_field => [ "@type", "unknown" ]
      }
  }

  #
  # ignore particularly useless lines
  #

  if [@message] =~ /^\s*$/ or [@message] =~ /^#.*$/ {
      drop { }
  }

  #
  # trim excess whitespace
  #

  mutate {
      strip => [ "@message" ]
  }
  if [@message] =~ "AWS_ACCESS_KEY_ID" {
    mutate {
      add_tag => ["_redacted"]
      gsub => [
        "@message", "AWS_ACCESS_KEY_ID=(.{3}).{17}", "AWS_ACCESS_KEY_ID=\1******"
      ]
    }
  }

  if [@message] =~ "AWS_SECRET_ACCESS_KEY" {
    mutate {
      add_tag => ["_redacted"]
      gsub => [
        "@message", "AWS_SECRET_ACCESS_KEY=(.{3}).{37}", "AWS_SECRET_ACCESS_KEY=\1******"
      ]
    }
  }

  if "_redacted" in [tags] {
    mutate {
      remove_tag => [ "_redacted" ]
      add_tag => ["redacted"]
    }
  }
  # syslog/relp

  grok {
      match => { "@message" => "(?:%{INT:syslog6587_msglen} )?<%{POSINT:syslog_pri}>(%{SPACE})?(?:%{NONNEGINT:syslog5424_ver} )?(?:%{SYSLOGTIMESTAMP:syslog_timestamp}|%{TIMESTAMP_ISO8601:syslog_timestamp}) %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?(:)? %{GREEDYDATA:syslog_message}" }
      match => { "@message" => "<%{POSINT:syslog_pri}>(%{SPACE})?%{SYSLOGTIMESTAMP:syslog_timestamp} %{DATA:syslog_program}\[%{POSINT:syslog_pid}\]: %{GREEDYDATA:syslog_message}" }
      add_tag => [ "syslog_standard" ]
      add_field => { "@raw" => "%{@message}"}
      tag_on_failure => ["fail/syslog_standard/_grokparsefailure"]
  }

  if !("fail/syslog_standard/_grokparsefailure" in [tags]) {
      syslog_pri { }

      date {
          match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
          timezone => "UTC"
          remove_field => "syslog_timestamp"
      }

      # Populate @source.host
      mutate {
          add_field => [ "[@source][host]", "%{syslog_hostname}" ]
      }

      mutate {
          convert => [ "syslog5424_ver", "integer" ]
          convert => [ "syslog6587_msglen", "integer" ]
      }

      if [syslog5424_ver] == 1 {
          grok {
              # I don't think this is rfc5424-legal because it says SD *must* exist and message *may* exist.
              # However, this makes parsing compatible with common syslog implementations.
              match => [ "syslog_message", "(?:%{DATA:syslog_procid}|\-) (?:%{DATA:syslog_msgid}|\-)(?: %{SYSLOG5424SD:syslog_sd}| \-)? %{GREEDYDATA:syslog_message}" ]
              overwrite => [
                  "syslog_message"
              ]
              tag_on_failure => [ "fail/syslog_standard/_grokparsefailure-syslog_standard-5424" ]
          }

          # structured-data
          if [syslog_sd] {
              grok {
                  match => [ "syslog_sd", "\[%{DATA:syslog_sd_id} (?<syslog_sd_params_raw>[^\]]+)\]" ]
                  remove_field => [
                      "syslog_sd"
                  ]
                  tag_on_failure => [ "fail/syslog_standard/_grokparsefailure-syslog_standard-5424/sds" ]
              }

              if !("fail/syslog_standard/_grokparsefailure-syslog_standard-5424/sd" in [tags]) {
                  # convert the the key-value pairs
                  kv {
                      source => "syslog_sd_params_raw"
                      target => "syslog_sd_params"
                      remove_field => [
                          "syslog_sd_params_raw"
                      ]
                  }
                  # When an additional host is specified in the sd_params, promote syslog_hostname to @shipper.host
                  # and replace @source.host with sd_params.host
                  if [syslog_sd_params][host] {
                    mutate {
                      add_field => { "[@shipper][host]" => "%{[syslog_hostname]}" }
                      replace => { "[@source][host]" => "%{[syslog_sd_params][host]}" }
                    }
                  }

                  if [syslog_sd_params][type] {
                     # when the syslog params include a type, prepare the message for parsing by additional downstream parsing rules:
                     #  - Change the @type - this triggers downstream parsing rules
                     #  - @message_body = 'unparsed' message body that will be parsed by downstream @type rules
                     mutate {
                         replace => { "@type" => "%{syslog_sd_params[type]}" }
                     }

                  }
              }
          }
      }

      # @message should contain the remaining unparsed text
      mutate {
        rename => { "syslog_message" => "@message" }
      }

  }
  # If the syslog program is a GUID then the log comes from an application
  if [syslog_program] =~ /^[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}$/ {
    grok {
      match => [ "syslog_procid", "\[%{GREEDYDATA:app_log_type}\/\d+\]" ]
      tag_on_failure => [ "app/log/type/fail" ]
    }

    mutate {
      add_field => { "[@source][app_id]" => "%{[syslog_program]}" }
    }

    mutate {
      update => { "syslog_program" => "app" }
      update => { "@type" => "LogMessage" }
      # This is an ugly hack to set the correct @source.component if the @type is "LogMessage"
      rename => { "app_log_type" => "[parsed_json_field][source_type]" }
    }

    # When a CF app is syslog drained the @source.host is org.space.app
    # e.g. admin.public.paas-admin
    # e.g. admin.monitoring.paas-metrics
    #
    # We want to index these as
    # @source.org_name
    # @source.space_name
    # @source.app_name
    #
    # to match @source.app_id above
    #
    # We want to split out the values in @source.host without modifying it
    mutate {
      copy => {
        "[@source][host]" => "splithost"
      }
    }

    # We split values and then index them
    mutate {
      split => {
        "splithost" => "."
      }

      add_field => {
        "[@source][org_name]" => "%{splithost[0]}"
        "[@source][space_name]" => "%{splithost[1]}"
        "[@source][app_name]" => "%{splithost[2]}"
      }
    }

    # Now we have indexed the split values we should remove the temporary field
    # so that it is not indexed as an array
    mutate {
      remove_field => ["splithost"]
    }
  }
  # NOTE: All parsed data should include @message, @level and @source.component.
  # Otherwise these fields are set from syslog_ fields in teardown script afterwards.

  # NOTE: @timestamp for CF components logs is set in logsearch-boshrelease from syslog_timestamp (timestamp set by metron_agent).
  # Timestamp set by metron_agent for Firehose logs is <message JSON>.timestamp field. (That's why app.conf snippet sets date with it).

  # Setup snippet (should precede all other snippets)
  ##--------------------------------
  # Setup conf. Sets general fields.|
  ##--------------------------------

  # Replace the unicode empty character \u0000 with ""
  # Drop useless logs
  mutate {
    gsub => [ "@message", '\u0000', ""]
  }
  if [@message] =~ /^\s*$/ or [@message] =~ /^#.*$/ {
    drop { }
  }

  # Set index
  # @index_type stores type of index: app/platform
  # [@metadata][index] stores full index prefix (for app logs additionally includes org and space name)
  mutate {
    add_field => { "@index_type" => "platform" } # by default logs go to 'platform'
  }
  if [syslog_program] == "doppler" {
    mutate {
      update => { "@index_type" => "app" }
    }
  }


  # Initialize @input, @shipper and @source
  mutate {
    add_field => { "@input" => "%{@type}" }

    rename => { "syslog_pri" => "[@shipper][priority]" }
    replace => { "[@shipper][name]" => "%{syslog_program}_%{[@type]}" }

    add_field => { "[@source][component]" => "%{syslog_program}" }
    add_field => { "[@source][type]" => "syslog" }
  }


  ##-- App
  # (App snippet should precede all other app snippets)
  ##--------------------------
  # App conf. Parses app logs.|
  ##--------------------------

  if [@index_type] == "app" {

      mutate {
        add_tag => [ "app" ]
      }

      # Parse Cloud Foundry logs from doppler firehose
      # (for message format see https://github.com/cloudfoundry-community/firehose-to-syslog
      # and https://github.com/cloudfoundry/dropsonde-protocol/tree/master/events)
      json {
        source => "@message"
        target => "parsed_json_field"
        id => "cloudfoundry/app/json"
      }

      if "_jsonparsefailure" in [tags] {

          # Amend the failure tag to match our fail/${addon}/${filter}/${detail} standard
          mutate {
              add_tag => ["fail/cloudfoundry/app/json"]
              remove_tag => ["_jsonparsefailure"]
          }

      } else {

          # Set @timestamp

          if [parsed_json_field][timestamp] or [parsed_json_field][start_timestamp] {

              # set @timestamp from event's timestamp if it is passed

              mutate {
                rename => { "[parsed_json_field][start_timestamp]" => "event_timestamp" } # HttpStartStop event case
                rename => { "[parsed_json_field][timestamp]" => "event_timestamp" }
                convert => { "event_timestamp" => "string" }
                gsub => ["event_timestamp", "\d{6}$", ""]
              }
              date {
                match => [ "event_timestamp", "UNIX_MS" ]
                remove_field => [ "event_timestamp" ]
              }
          } else if [parsed_json_field][time] {

              # if event's timestamp is not passed then we set @timestamp = event shipping time from firehose-to-syslog

              date {
                match => [ "[parsed_json_field][time]", "ISO8601"]
              }
          }
          mutate {
            remove_field => [ "[parsed_json_field][time]" ]
          }


          # Set @message and @level

          # 1) Replace the unicode \u2028 with \n, which Kibana will display as a new line.
          # 2) Replace the unicode Null character \u0000 with ""
          mutate {
            gsub => [ "[parsed_json_field][msg]", '\u2028', "
  " # Seems that passing a string with an actual newline in it is the only way to make gsub work.
            ]
            gsub => [ "[parsed_json_field][msg]", '\u0000', ""]
          }

          mutate {
            rename => { "[parsed_json_field][msg]" => "@message" } # @message
            rename => { "[parsed_json_field][level]" => "@level" } # @level
          }

          # Set @source fields
          mutate {
            rename => { "[parsed_json_field][ip]"          => "[@source][host]" }
            rename => { "[parsed_json_field][deployment]"  => "[@source][deployment]" }
            rename => { "[parsed_json_field][job]"         => "[@source][job]" }
            rename => { "[parsed_json_field][job_index]"   => "[@source][job_index]" }
            # override
            rename => { "[parsed_json_field][origin]"      => "[@source][component]" }
          }

          if ![parsed_json_field][event_type] {
            mutate {
              add_field => { "[parsed_json_field][event_type]" => "UnknownEvent" }
            }
          }

          # Set @type (based on event_type)
          mutate {
            replace => { "@type" => "%{[parsed_json_field][event_type]}" }
          }

          # Set [@source][type] (based on @type by default,
          # for LogMessage we override it with source_type field that comes in event's json)
          translate {
            field => "@type"
            dictionary => [ "LogMessage",       "LOG",
                            "Error",            "ERR",
                            "ContainerMetric",  "CONTAINER",
                            "ValueMetric",      "METRIC",
                            "CounterEvent",     "COUNT",
                            "HttpStartStop",    "HTTP"
            ]
            destination => "[@source][type]"
            override => true
            fallback => "NA"
          }

          # Set @cf fields
          mutate {
            rename => { "[parsed_json_field][cf_org_id]"     => "[@cf][org_id]" }
            rename => { "[parsed_json_field][cf_org_name]"   => "[@cf][org]" }
            rename => { "[parsed_json_field][cf_space_id]"   => "[@cf][space_id]" }
            rename => { "[parsed_json_field][cf_space_name]" => "[@cf][space]" }
            rename => { "[parsed_json_field][cf_app_id]"     => "[@cf][app_id]" }
            rename => { "[parsed_json_field][cf_app_name]"   => "[@cf][app]" }

            remove_field => "[parsed_json_field][cf_origin]"  # cf_origin = firehose all the time
            remove_field => "[parsed_json_field][cf_ignored_app]"  # cf_ignored_app = false all the time (https://github.com/cloudfoundry-community/firehose-to-syslog/issues/137)
          }

          # Define [parsed_json_field_name]
          mutate {
            add_field => { "parsed_json_field_name" => "%{@type}"}
          }

          # Override @metadata.index
          if [@cf][org] {
              mutate { replace => { "[@metadata][index]" => "%{[@metadata][index]}-%{[@cf][org]}" } }
              if [@cf][space] {
                  mutate { replace => { "[@metadata][index]" => "%{[@metadata][index]}-%{[@cf][space]}" } }
              }
              mutate { lowercase => [ "[@metadata][index]" ] }
          }
      }

  }

  # special cases parsing
  ##------------------------------------------------------------
  # General parsing of LogMessage events.                       |
  # A LogMessage contains a "log line" and associated metadata. |
  ##------------------------------------------------------------

  if([@type] == "LogMessage") {

      mutate {
        add_tag => [ "logmessage" ]
      }

      # Drop useless message log.
      if [@message] =~ /^\s*$/ or [@message] =~ /^#.*$/ {
          drop { }
      }

      # Override [@source][type]
      mutate {
        rename => { "[parsed_json_field][source_type]" => "[@source][type]" }
        uppercase => [ "[@source][type]" ] # uppercase for consistency
      }

      # Set [@cf][app_instance]
      if [@cf][app_id] and [@cf][app_id] != "" {
          mutate {
            rename => { "[parsed_json_field][source_instance]" => "[@cf][app_instance]" }
            convert => { "[@cf][app_instance]" => "integer" }
          }
      } else {
          mutate {
            remove_field => "[@cf][app_id]"
            remove_field => "[parsed_json_field][source_instance]"
          }
      }
  }

  ##------------------------------
  ## Parses LogMessage APP events.|
  ##------------------------------

  if [@type] == "LogMessage" and [@source][type] =~ /APP(|\/.*)$/ {

      mutate {
        add_tag => [ "logmessage-app" ]
      }

      mutate {
        # Firehose sets values like "APP/PROC/WEB". Rename just to "APP" for simplicity.
        replace => { "[@source][type]" => "APP" }
      }

      # Parse application logs based on msg format.
      # Marks unknown format with [unknown_msg_format] tag.

      ## ---- Format 1: JSON
      if [@message] =~ /^\s*{".*}\s*$/ { # if it looks like JSON

          json {
              source => "@message"
              target => "app"
              id => "cloudfoundry/app-app/json"
          }

          if !("_jsonparsefailure" in [tags]) {

              mutate {
                  rename => { "[app][message]" => "@message" } # @message
              }
              # concat message and exception
              if [app][exception] {
                  mutate {
                      ## NOTE: keep line break and new line spacing (new line is inserted in logstash in such a way)
                      replace => { "@message" => "%{@message}
  %{[app][exception]}" }
                      remove_field => [ "[app][exception]" ]
                }
              }

              mutate {
                  rename => { "[app][level]" => "@level" } # @level
              }

          } else {

              mutate {
                  add_tag => [ "unknown_msg_format" ]
                  remove_tag => ["_jsonparsefailure"]
              }
          }

      ## ---- Format 2: "[CONTAINER] .." (Tomcat logs)
      } else if [@message] =~ /^\s*\[CONTAINER\]/ {

          # Tomcat specific parsing (in accordance with https://github.com/cloudfoundry/java-buildpack-support/blob/master/tomcat-logging-support/src/main/java/com/gopivotal/cloudfoundry/tomcat/logging/CloudFoundryFormatter.java)
          grok {
              match => [ "@message", "(?<app_logger>\[CONTAINER\]%{SPACE}%{NOTSPACE})%{SPACE}%{LOGLEVEL:@level}%{SPACE}%{GREEDYDATA:@message}" ]
              overwrite => [ "@message", "@level" ]
              tag_on_failure => [ "unknown_msg_format" ]
              id => "cloudfoundry/app-app/tomcat/grok"
          }
          mutate {
              rename => { "app_logger" => "[app][logger]" }
          }

      } else {

          ## ---- Format 3: Logback status logs
          grok {
              match => [ "@message", "%{TIME} \|\-%{LOGLEVEL:@level} in %{NOTSPACE:[app][logger]} - %{GREEDYDATA:@message}" ]
              overwrite => [ "@message", "@level" ]

              ## ---- Unknown Format: if no formats succeeded set with 'unknown_msg_format' tag
              tag_on_failure => [ "unknown_msg_format" ]
              id => "cloudfoundry/app-app/logback/grok"
          }
      }

  }

  ##------------------------------
  ## Parses LogMessage RTR events.|
  ##------------------------------

  if ( [@type] == "LogMessage" and [@source][type] == "RTR" ) {

      mutate {
        add_tag => [ "logmessage-rtr" ]
      }

      grok {
        match => [ "@message", [
          # cf-deployment v12.27.0+
          "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{TIMESTAMP_ISO8601})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" \"(%{IPORHOST:[rtr][src][host]}:%{POSINT:[rtr][src][port]:int}|-)\" \"%{IPORHOST:[rtr][dst][host]}:%{POSINT:[rtr][dst][port]:int}\" x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} gorouter_time:%{NUMBER:[rtr][gorouter_time_sec]:float} app_id:\"%{NOTSPACE:[rtr][app][id]}\" app_index:\"(%{BASE10NUM:[rtr][app][index]:int}|-)\"( %{GREEDYDATA:kvpairs})?", 
          # cf-deployment v12.17.0+
          "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{YEAR}-%{MONTHNUM}-%{MONTHDAY}T%{TIME}+%{INT})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" \"%{IPORHOST:[rtr][src][host]}:%{POSINT:[rtr][src][port]:int}\" \"%{IPORHOST:[rtr][dst][host]}:%{POSINT:[rtr][dst][port]:int}\" x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} gorouter_time:%{NUMBER:[rtr][gorouter_time_sec]:float} app_time:%{NUMBER:[rtr][app_time_sec]:float} app_id:\"%{NOTSPACE:[rtr][app][id]}\" app_index:\"%{BASE10NUM:[rtr][app][index]:int|-}\"",
          # cf-release v252+
          "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{YEAR}-%{MONTHNUM}-%{MONTHDAY}T%{TIME}+%{INT})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" \"(%{IPORHOST:[rtr][src][host]}:%{POSINT:[rtr][src][port]:int}|-)\" \"%{IPORHOST:[rtr][dst][host]}:%{POSINT:[rtr][dst][port]:int}\" x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} app_id:\"%{NOTSPACE:[rtr][app][id]}\" app_index:\"(%{BASE10NUM:[rtr][app][index]:int}|-)\"",
          # cf-release v250+
          "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" \"(%{HOSTPORT}|-)\" \"(%{HOSTPORT}|-)\" x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} app_id:%{NOTSPACE}%{GREEDYDATA}",
          # older
          "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" %{HOSTPORT} x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} app_id:%{NOTSPACE}%{GREEDYDATA}"
          ]
        ]
        id => "cloudfoundry/app-rtr/grok"

        tag_on_failure => [ "fail/cloudfoundry/app-rtr/grok" ]
      }

      if !("fail/cloudfoundry/app-rtr/grok" in [tags]) {

          # Set [rtr][timestamp]
          mutate {
            rename => { "rtr_time" => "[rtr][timestamp]" }
          }

          # Set [rtr][x_forwarded_for]
          mutate {
              gsub => ["[rtr][x_forwarded_for]","[\s\"]",""] # remove quotes and whitespace
              split => ["[rtr][x_forwarded_for]", ","] # format is client, proxy1, proxy2 ...
          }

          # Set [rtr][remote_addr]
          mutate {
            add_field => ["[rtr][remote_addr]", "%{[rtr][x_forwarded_for][0]}"]
          }
          if [rtr][remote_addr] =~ /([0-9]{1,3}\.){3}[0-9]{1,3}/ {
              geoip {
                source => "[rtr][remote_addr]"
              }
          }

          # Set [rtr][response_time_ms]
          mutate {
            add_field => { "[rtr][response_time_ms]" => "%{[rtr][response_time_sec]}000" }
          }
          mutate {
            gsub => ["[rtr][response_time_ms]", "\.(\d)(\d)(\d)([\d]{0,3}).*","\1\2\3.\4"]
          }
          mutate {
            convert => { "[rtr][response_time_ms]" => "float" }
          }

          # Set [rtr][gorouter_time_ms]
          if [rtr][gorouter_time_sec] =~ /.+/ {
            mutate {
              add_field => { "[rtr][gorouter_time_ms]" => "%{[rtr][gorouter_time_sec]}000" }
            }
            mutate {
              gsub => ["[rtr][gorouter_time_ms]", "\.(\d)(\d)(\d)([\d]{0,3}).*","\1\2\3.\4"]
            }
            mutate {
              convert => { "[rtr][gorouter_time_ms]" => "float" }
            }
          }

          # Process extra headers based on the following 2 properties available in CF-Deployment
          #   https://bosh.io/jobs/gorouter?source=github.com/cloudfoundry/routing-release&version=0.198.0#p%3drouter.extra_headers_to_log
          #   https://bosh.io/jobs/gorouter?source=github.com/cloudfoundry/routing-release&version=0.198.0#p%3drouter.tracing.enable_zipkin
          if [kvpairs] =~ /.+/ {
            kv {
              source => "kvpairs"
              remove_field => [ "kvpairs" ]
              include_brackets => false
              value_split => ":"
              target => "[rtr][extra]"
            }
          }

          # Set @message
          mutate {
            replace => {"@message" => "%{[rtr][status]} %{[rtr][verb]} %{[rtr][path]} (%{[rtr][response_time_ms]} ms)"}
          }

          # Set @level (based on HTTP status)
          if [rtr][status] >= 500 {
              mutate {
                replace => { "@level" => "ERROR" }
              }
          } else if [rtr][status] >= 400 {
              mutate {
                replace => { "@level" => "WARN" }
              }
          } else {
              mutate {
                replace => { "@level" => "INFO" }
              }
          }
      }

  }

  ##---------------------------------------------------------------
  # Parses app Error events.                                       |
  # An Error event represents an error in the originating process. |
  ##---------------------------------------------------------------
  if( [@type] == "Error" ) {

      mutate {
        add_tag => [ "error" ]

        rename => { "[parsed_json_field][message]" => "@message" }
      }
  }

  ##------------------------------------------------------------------
  # Parses ContainerMetric message.                                   |
  # A ContainerMetric records resource usage of an app in a container.|
  ##------------------------------------------------------------------
  if( [@type] == "ContainerMetric" ) {

      mutate {
        add_tag => [ "containermetric" ]
      }

      # related application
      if [@cf][app_id] and [@cf][app_id] != "" {
          mutate {
            rename => { "[parsed_json_field][instance_index]" => "[@cf][app_instance]" }
          }
      } else {
          mutate {
            remove_field => "[@cf][app_id]"
            remove_field => "[parsed_json_field][instance_index]"
          }
      }

      # @message
      mutate {
        replace => {"@message" => "cpu=%{[parsed_json_field][cpu_percentage]}, memory=%{[parsed_json_field][memory_bytes]}, disk=%{[parsed_json_field][disk_bytes]}"}
      }
  }

  ##---------------------------------------------------------------------
  # Parses ValueMetric message.                                          |
  # A ValueMetric indicates the value of a metric at an instant in time. |
  ##---------------------------------------------------------------------
  if( [@type] == "ValueMetric" ) {

      mutate {
        add_tag => [ "valuemetric" ]

        replace => {"@message" => "%{[parsed_json_field][name]} = %{[parsed_json_field][value]} (%{[parsed_json_field][unit]})"}
      }
  }

  ##------------------------------------------------------
  # Parses CounterEvent message.                          |
  # A CounterEvent represents the increment of a counter. |
  ##------------------------------------------------------
  if( [@type] == "CounterEvent" ) {

      mutate {
        add_tag => [ "counterevent" ]

        replace => {"@message" => "%{[parsed_json_field][name]} (delta=%{[parsed_json_field][delta]}, total=%{[parsed_json_field][total]})"}
      }
  }

  ##--------------------------------------------------------------------------
  # Parses HttpStartStop event.                                               |
  # An HttpStartStop event represents the whole lifecycle of an HTTP request. |
  ##--------------------------------------------------------------------------
  if( [@type] == "HttpStartStop" ) {

      mutate {
        add_tag => [ "http" ]
      }

      # Related application
      if ![parsed_json_field][instance_id] or [parsed_json_field][instance_id] == "" {
          mutate {
            remove_field => "[parsed_json_field][instance_id]"
            remove_field => "[parsed_json_field][instance_index]"
          }
      }

      # Set @message
      mutate {
        replace => {"@message" => "%{[parsed_json_field][status_code]} %{[parsed_json_field][method]} %{[parsed_json_field][uri]} (%{[parsed_json_field][duration_ms]} ms)"}
      }

  }


  ##-- Platform
  # (Platform snippet should precede all other platform snippets)
  ##------------------------------
  # Platform conf. Parses CF logs.|
  ##------------------------------
  if [@index_type] == "platform" and [@source][component] != "app" {

      mutate {
          replace => { "[@source][type]" => "system" } # default for platform logs
          add_tag => "platform"
      }

      # Syslog message with RFC 5424 and the enterprise number is CF
      if [syslog_sd_id] == "instance@47450" {
          mutate {
              add_field => {
                  "[@source][az]" => "%{[syslog_sd_params][az]}"
                  "[@source][deployment]" => "%{[syslog_sd_params][deployment]}"
                  "[@source][director]" => "%{[syslog_sd_params][director]}"
                  "[@source][id]" => "%{[syslog_sd_params][id]}"
                  "[@source][job]" => "%{[syslog_sd_params][group]}"
              }
              replace => {
                  "[@source][type]" => "cf"
                  "@type" => "cf"
              }
              add_tag => "cf"
          }
      } else {
          # Try parsing with possible CF formats
          grok {
              # Metron agent format (https://github.com/cloudfoundry/loggregator/blob/master/jobs/metron_agent/templates/syslog_forwarder.conf.erb#L53)
              match => [ "@message", "\[job=%{NOTSPACE:[@source][job]} index=%{INT:[@source][index]:int}\]%{SPACE}%{GREEDYDATA:@message}" ]

              # Syslog release format (https://github.com/cloudfoundry/syslog-release/blob/master/jobs/syslog_forwarder/templates/rsyslog.conf.erb#L56)
              match => [ "@message", "\[bosh instance=%{NOTSPACE:[@source][deployment]}/%{NOTSPACE:[@source][job]}/%{NOTSPACE:[@source][job_index]}\]%{SPACE}%{GREEDYDATA:@message}" ]

              overwrite => [ "@message" ] # @message
              id => "cloudfoundry/platform/grok"
              tag_on_failure => "fail/cloudfoundry/platform/grok"
          }

          if !("fail/cloudfoundry/platform/grok" in [tags]) {
              mutate {
                  replace => { "[@source][type]" => "cf" }
                  replace => { "@type" => "cf" }
                  add_tag => "cf"
              }
          }
      }
  }

  # special cases parsing
  ##----------------------------------
  # Haproxy conf. Parses haproxy logs.|
  ##----------------------------------
  if [@source][component] == "haproxy" {

      mutate {
        replace => { "@type" => "haproxy" }
        add_tag => "haproxy"
      }

      # Grok patterns are based on http://www.haproxy.org/download/1.7/doc/configuration.txt
      # Two formats are used accordingly:
      # 8.2.3. HTTP log format
      # 8.2.5. Error log format

      grok {
        match => [ "@message", "%{IP:[haproxy][client_ip]}:%{INT:[haproxy][client_port]:int} \[%{DATA:[haproxy][accept_date]}\] %{NOTSPACE:[haproxy][frontend_name]} %{NOTSPACE:[haproxy][backend_name]}/%{NOTSPACE:[haproxy][server_name]} %{INT:[haproxy][time_request]:int}/%{INT:[haproxy][time_queue]:int}/%{INT:[haproxy][time_backend_connect]:int}/%{INT:[haproxy][time_backend_response]:int}/%{INT:[haproxy][time_duration]:int} %{INT:[haproxy][http_status_code]:int} %{NOTSPACE:[haproxy][bytes_read]:int} %{DATA:[haproxy][captured_request_cookie]} %{DATA:[haproxy][captured_response_cookie]} %{NOTSPACE:[haproxy][termination_state]} %{INT:[haproxy][actconn]:int}/%{INT:[haproxy][feconn]:int}/%{INT:[haproxy][beconn]:int}/%{INT:[haproxy][srvconn]:int}/%{NOTSPACE:[haproxy][retries]:int} %{INT:[haproxy][srv_queue]:int}/%{INT:[haproxy][backend_queue]:int} (\{%{DATA:[haproxy][captured_request_headers]}\})?( )?(\{%{DATA:[haproxy][captured_response_headers]}\})?( )?\"(?<message>(?<haproxy_http_request>(<BADREQ>|((%{WORD:[haproxy][http_request_verb]})?( %{GREEDYDATA})?))))\"" ]
        match => [ "@message", "%{IP:[haproxy][client_ip]}:%{INT:[haproxy][client_port]:int} \[%{DATA:[haproxy][accept_date]}\] %{NOTSPACE:[haproxy][frontend_name]}/%{NOTSPACE:[haproxy][bind_name]}:%{SPACE}%{GREEDYDATA:message}" ]
        id => "cloudfoundry/platform-haproxy/grok"
        tag_on_failure => "fail/cloudfoundry/platform-haproxy/grok"
      }

      if !("fail/cloudfoundry/platform-haproxy/grok" in [tags]) {

          if [haproxy_http_request] {
              mutate {
                rename => {"haproxy_http_request" => "[haproxy][http_request]"}
              }
          }

          mutate {
            rename => {"message" => "@message"} # @message
          }

          # @level
          if [haproxy][http_status_code] {
              if [haproxy][http_status_code] >= 400 {
                  mutate {
                    add_field => { "@level" => "ERROR" }
                  }
              } else {
                  mutate {
                    add_field => { "@level" => "INFO" }
                  }
              }
          }
      }
  }

  ##--------------------------
  # Uaa conf. Parses uaa logs.|
  ##--------------------------
  if [@source][component] == "uaa" {

      # ---- Parse UAA events (general)

      mutate {
        replace => { "[@source][component]" => "uaa" } # remove vcap. prefix
        replace => { "@type" => "uaa" }
        add_tag => "uaa"
      }

      grok {
        match => { "@message" => "\[%{TIMESTAMP_ISO8601:[uaa][timestamp]}\]%{SPACE}uaa%{SPACE}-%{SPACE}%{NUMBER:[uaa][pid]:int}%{SPACE}\[%{DATA:[uaa][thread]}\]%{SPACE}....%{SPACE}%{LOGLEVEL:@level}%{SPACE}---%{SPACE}%{DATA:[uaa][log_category]}:%{SPACE}%{GREEDYDATA:@message}"}
        overwrite => ["@message", "@level"] # @message, @level
        id => "cloudfoundry/platform-uaa/grok"
        tag_on_failure => "fail/cloudfoundry/platform-uaa/grok"
      }

      if [uaa][log_category] == "Audit" {

          # override
          mutate {
            replace => { "@type" => "uaa-audit" }
            add_tag => "audit"
          }

          # ---- Additional parsing: Audit events

          grok {
            match => { "@message" => "(?<uaa_audit_message>(%{WORD:[uaa][audit][type]}%{SPACE}\('%{DATA:[uaa][audit][data]}'\))):%{SPACE}principal=%{DATA:[uaa][audit][principal]},%{SPACE}origin=\[%{DATA:[uaa][audit][origin]}\],%{SPACE}identityZoneId=\[%{DATA:[uaa][audit][identity_zone_id]}\]"}
            id => "cloudfoundry/platform-uaa/audit/grok"
            tag_on_failure => "fail/cloudfoundry/platform-uaa/audit/grok"
          }

          if !("fail/cloudfoundry/platform-uaa/audit/grok" in [tags]) {

              # Audit @message
              mutate {
                rename => { "uaa_audit_message" => "@message" }
              }

              # extract audit_event_remote_address and geoip it
              if "PrincipalAuthenticationFailure" == [uaa][audit][type] {
                  mutate {
                    add_field => { "[uaa][audit][remote_address]" => "%{[uaa][audit][origin]}" }
                  }
              }
              if [uaa][audit][origin] =~ /remoteAddress=/ {
                  grok {
                    match => { "[uaa][audit][origin]" => "remoteAddress=%{IP:[uaa][audit][remote_address]}" }
                    id => "cloudfoundry/platform-uaa/audit/origin/grok"
                  }
              }
              if [uaa][audit][remote_address] {
                 geoip {
                   source => "[uaa][audit][remote_address]"
                 }
              }

              # split origin
              mutate {
                split =>  { "[uaa][audit][origin]" => ", " }
              }

          }

      }
  }


  ##-----------------------------
  # Vcap conf. Parses vcap* logs.|
  ##-----------------------------
  if [@source][component] != "uaa" and [@source][component] != "app" {

      # minus vcap. prefix
      mutate {
        gsub => ["[@source][component]", "^vcap\.", ""]
      }

      mutate {
        replace => { "@type" => "vcap" }
        add_tag => "vcap"
      }

      # Parse Cloud Foundry logs
      if [@message] =~ /^\s*{".*}\s*$/ { # looks like JSON

          # parse JSON message
          json {
              source => "@message"
              target => "parsed_json_field"
              remove_field => [ "@message" ]
              add_field => { "parsed_json_field_name" => "%{[@source][component]}"}
              id => "cloudfoundry/platform-vcap/json"
          }

          if "_jsonparsefailure" in [tags] {
              # Amend the failure tag to match our fail/${addon}/${filter}/${detail} standard
              mutate {
                  add_tag => ["fail/cloudfoundry/platform-vcap/json"]
                  remove_tag => ["_jsonparsefailure"]
              }

          } else {

              mutate {
                  rename => { "[parsed_json_field][message]" => "@message" } # @message
              }

              # @level
              translate {
                  field => "[parsed_json_field][log_level]"
                  dictionary => [ "0", "DEBUG", "1", "INFO", "2", "ERROR", "3", "FATAL" ]
                  destination => "@level"
                  override => true
                  fallback => "%{[parsed_json_field][log_level]}"
                  remove_field => "[parsed_json_field][log_level]"
              }
          }

      }
  }

  ##------------------------------------+
  # Gorouter conf. Parses gorouter logs.|
  ##------------------------------------+

  if [@index_type] == "platform" and [@source][component] == "gorouter" {
      if [@message] =~ "\A\{.+\}\z" {
          json {
              source => "@message"
              add_tag => [ "router/syslog" ]
              tag_on_failure => [ "router/parsing_failed" ]
              id => "router/accesslog/json"
          }
      } else {
          grok {
              match => [ "@message", [
                  # cf-deployment v12.27.0+
                  "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{TIMESTAMP_ISO8601})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" \"%{IPORHOST:[rtr][src][host]}:%{POSINT:[rtr][src][port]:int}\" \"%{IPORHOST:[rtr][dst][host]}:%{POSINT:[rtr][dst][port]:int}\" x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} gorouter_time:%{NUMBER:[rtr][gorouter_time_sec]:float} app_id:\"%{NOTSPACE:[rtr][app][id]}\" app_index:\"(%{BASE10NUM:[rtr][app][index]:int}|-)\"( %{GREEDYDATA:kvpairs})?",
                  # cf-deployment v12.17.0+
                  "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{YEAR}-%{MONTHNUM}-%{MONTHDAY}T%{TIME}+%{INT})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" \"%{IPORHOST:[rtr][src][host]}:%{POSINT:[rtr][src][port]:int}\" \"%{IPORHOST:[rtr][dst][host]}:%{POSINT:[rtr][dst][port]:int}\" x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} gorouter_time:%{NUMBER:[rtr][gorouter_time_sec]:float} app_time:%{NUMBER:[rtr][app_time_sec]:float} app_id:\"%{NOTSPACE:[rtr][app][id]}\" app_index:\"%{BASE10NUM:[rtr][app][index]:int}\"",
                  # cf-release v252+
                  "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{YEAR}-%{MONTHNUM}-%{MONTHDAY}T%{TIME}+%{INT})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" \"(%{IPORHOST:[rtr][src][host]}:%{POSINT:[rtr][src][port]:int}|-)\" \"%{IPORHOST:[rtr][dst][host]}:%{POSINT:[rtr][dst][port]:int}\" x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} app_id:\"%{NOTSPACE:[rtr][app][id]}\" app_index:\"(%{BASE10NUM:[rtr][app][index]:int}|-)\"",
                  # cf-release v250+
                  "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" \"(%{HOSTPORT}|-)\" \"(%{HOSTPORT}|-)\" x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} app_id:%{NOTSPACE}%{GREEDYDATA}", 
                  # very old
                  "^%{HOSTNAME:[rtr][hostname]} - \[(?<rtr_time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\] \"%{WORD:[rtr][verb]} %{URIPATHPARAM:[rtr][path]} %{PROG:[rtr][http_spec]}\" %{BASE10NUM:[rtr][status]:int} %{BASE10NUM:[rtr][request_bytes_received]:int} %{BASE10NUM:[rtr][body_bytes_sent]:int} \"%{GREEDYDATA:[rtr][referer]}\" \"%{GREEDYDATA:[rtr][http_user_agent]}\" %{HOSTPORT} x_forwarded_for:\"%{GREEDYDATA:[rtr][x_forwarded_for]}\" x_forwarded_proto:\"%{GREEDYDATA:[rtr][x_forwarded_proto]}\" vcap_request_id:\"%{NOTSPACE:[rtr][vcap_request_id]}\" response_time:%{NUMBER:[rtr][response_time_sec]:float} app_id:%{NOTSPACE}%{GREEDYDATA}"
                  ]
              ]
              id => "router/accesslog/grok"
              overwrite => [ "@message" ]
              add_tag => "router/accesslog"
              tag_on_failure => "router/parsing_failed"
          }

      }
  }


  # Teardown snippet (should follow all other snippets)
  ##----------------------------------------------------------
  # Teardown conf. Performs fields post-processing & clean up.|
  ##----------------------------------------------------------

  # -- Apply default settings for mandatory fields (if not set)

  # set syslog @level (if @level is not set yet)
  if ![@level] and [syslog_severity_code] { # @level

      if [syslog_severity_code] <= 3 { # 0-Emergency, 1-Alert, 2-Critical, 3-Error
          mutate {
            add_field => { "@level" => "ERROR" }
          }
      } else if [syslog_severity_code] <= 5 { # 4-Warning, 5-Notice
          mutate {
            add_field => { "@level" => "WARN" }
          }
      } else if [syslog_severity_code] == 6 { # 6-Informational
          mutate {
            add_field => { "@level" => "INFO" }
          }
      } else if [syslog_severity_code] == 7 { #7-Debug
          mutate {
            add_field => { "@level" => "DEBUG" }
          }
      }
  }
  mutate {
    uppercase => [ "@level" ]
  }

  # -- Rework fields

  if [@source][job] and [@source][index] {
    mutate { add_field => { "[@source][vm]" => "%{[@source][job]}/%{[@source][index]}" } }
  }

  if ![@source][host] {
      mutate { rename => { "[host]" => "[@source][host]" } }
  }

  # Downcase [parsed_json_field_name] and replace special characters with '_')..
  # .. and rename dynamic [parsed_json_field] field to this calculated name.
  if [parsed_json_field] and [parsed_json_field_name] {
      mutate {
        lowercase => [ "parsed_json_field_name" ]
        gsub => [ "parsed_json_field_name", "[\s/\\?#-\.]", "_" ]
      }
      mutate {
        rename => { "parsed_json_field" => "%{parsed_json_field_name}" }
      }
  }

  mutate {
    remove_field => [ "parsed_json_field_name" ]
  }

  # -- Cleanup unnecessary fields

  # Remove syslog_ fields
  mutate {
    remove_field => "syslog_pri"
    remove_field => "syslog_facility"
    remove_field => "syslog_facility_code"
    remove_field => "syslog_message"
    remove_field => "syslog_severity"
    remove_field => "syslog_severity_code"
    remove_field => "syslog_program"
    remove_field => "syslog_timestamp"
    remove_field => "syslog_hostname"
    remove_field => "syslog_pid"
  }

  # Cleanup
  mutate {
    remove_field => [ "@version", "host", "port", "_logstash_input" ]
  }

  if [@level] == "INFO" and [@message] =~ /type=SYSCALL msg=audit.* syscall=(159|54) success=yes/ {
    # These are so high volume, and as Linux audit syscall logs they're basically debug anyway. Keep other types of audit logs as they may be useful and lower volume.
    # 54 is setsockopt, 159 is adjtimex. Reference available at https://filippo.io/linux-syscall-table/
    mutate {
      replace => { "@level" => "DEBUG" }
    }
  }

  # Drop debug logs
  if [@level] == "DEBUG" {
      drop { }
  }

  # Drop potentially sensitive log lines from the Cloud Controller job queue
  if [@source][component] =~ "cloud_controller" {
    if [@message] =~ "about to run job" {
      drop { }
    }
  }

  if [garden][data][spec] == "" {
    mutate {
      remove_field => [ "[garden][data][spec]" ]
    }
  }
  if [@source][component] == "gorouter" {
    mutate { replace => { "type" => "gorouter" } }
    grok {
      match => {
        "@message" =>
          '%{HOSTNAME:[gorouter][host]} - \[%{TIMESTAMP_ISO8601:[gorouter][timestamp]}\] "%{WORD:[gorouter][method]} %{URIPATHPARAM:[gorouter][request]} %{NOTSPACE:[gorouter][httpversion]}" %{BASE10NUM:[gorouter][status]} %{BASE10NUM:[gorouter][bytesreceived]} %{BASE10NUM:[gorouter][bytessent]} %{QUOTEDSTRING:[gorouter][referer]} %{QUOTEDSTRING:[gorouter][useragent]} %{QUOTEDSTRING:[gorouter][clientaddr]} %{QUOTEDSTRING:[gorouter][upstreamaddr]} %{GREEDYDATA:routerkeys}'
        }
      add_tag => ["gorouter", "gorouter_access_log"]
    }
    kv {
      source => "routerkeys"
      target => "[gorouter][header]"
      value_split => ":"
      remove_field => "routerkeys"
    }
  }
  date {
    match => [ "[gorouter][timestamp]", "ISO8601" ]
    target => "@timestamp"
  }
  mutate {
    remove_field => [ "[gorouter][timestamp]" ]
  }
  if [@source][component] == "vcap_nginx_access" {
    grok {
      match => {
        "@message" =>
        '%{IPORHOST:[nginx][clientip]} - \[%{HTTPDATE:[nginx][timestamp]}\] "%{WORD:[nginx][verb]} %{URIPATHPARAM:[nginx][request]} HTTP/%{NUMBER:[nginx][httpversion]}" %{NUMBER:[nginx][response]} (?:%{NUMBER:[nginx][bytes]}|-) (?:"(?:%{URI:[nginx][referrer]}|-)"|%{QS:[nginx][referrer]}) %{QS:[nginx][agent]} %{DATA:[nginx][x_forwarded_for]} vcap_request_id:%{UUID:[nginx][external_vcap_request_id]}(::%{UUID:[nginx][internal_vcap_request_id]})? response_time:%{NUMBER:[nginx][response_time]}'
        }
    }

    if ([nginx][internal_vcap_request_id]) {
      mutate {
        add_field => {
          "[nginx][vcap_request_id]" => "%{[nginx][external_vcap_request_id}::%{[nginx][internal_vcap_request_id]}"
        }
      }
    } else {
      mutate {
        copy => { "[nginx][external_vcap_request_id]" => "[nginx][vcap_request_id]" }
      }
    }
  }
  if [@source][component] == "cloud_controller_ng" {
    grok {
      match => {
        "@message" =>
        'Started %{WORD:[cloud_controller_ng][method]} "%{URIPATHPARAM:[cloud_controller_ng][uri]}" for user: (%{UUID:[cloud_controller_ng][user]})?, ip: %{IP:[cloud_controller_ng][source_ip]}'
        }
    }
  }
  date {
    match => [ "[nginx][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601" ]
    target => "@timestamp"
  }
  mutate {
    remove_field => [ "[nginx][timestamp]" ]
  }

  # If the JSON message was succesfully parsed and @message is still in JSON, then we can remove it
  if [@source][component] == "app" and !("unknown_msg_format" in [tags]) and [@message] =~ /^\s*{".*}\s*$/ {
    mutate {
      remove_field => "@message"
    }
  }

  # Remove unnecessary or empty fields
  mutate {
    remove_field => [
      "syslog5424_ver",
      "syslog6587_msglen",
      "syslog_msgid",
      "syslog_procid",
      "syslog_sd_id"
    ]
  }

  # Some gorouter fields are numbers
  mutate {
    convert => {
      "[gorouter][header][response_time]" => "float"
      "[gorouter][header][gorouter_time]" => "float"
      "[gorouter][header][app_time]" => "float"
      "[gorouter][bytessent]" => "integer"
      "[gorouter][bytesreceived]" => "integer"
    }
  }
  # `paas-billing` provides the value of DEPLOY_ENV through an
  # `app.data.deployment` field. We want to set `@source.deployment` so
  # that it can be queried like the rest of the platform.
  if [app][source] == "paas-billing" {
    mutate {
      add_field => { "[@source][deployment]" => "%{[app][data][deployment]}" }
    }
  }
# Use more accurate timestamp fields, instead of the timestamp of when logit received the log

  date {
    match => [ "[aiven_service_discovery][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[auctioneer][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[bbs][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[cc_deployment_updater][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[cc_uploader][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[cdn_broker][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[cdn_cron][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[cloud_controller_clock][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[cloud_controller_ng][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[cloud_controller_worker][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[elasticache_broker][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[eventgenerator][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[file_server][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[garden][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[golangapiserver][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[locket][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[metricsforwarder][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[policy_server][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[rds_broker][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[rds_metric_collector][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[rep][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[route_emitter][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[route_registrar][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[s3_broker][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[scalingengine][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[sqs_broker][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[ssh_proxy][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[tps][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
  date {
    match => [ "[vxlan_policy_agent][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601", "UNIX" ]
    target => "@timestamp"
  }
}
