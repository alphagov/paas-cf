releases:
- name: logsearch
  url: https://bosh.io/d/github.com/logsearch/logsearch-boshrelease?v=200.0.0
  version: 200.0.0
  sha1: 527c35db31cd66810accf128ceffee4f5fde80c3
- name: logsearch-shipper
  url: https://bosh.io/d/github.com/logsearch/logsearch-shipper-boshrelease?v=4
  version: 4
  sha1: c92ce357c5e1e77a4fb7944d58a1971c7aee06b0

resource_pools:
- name: ingestor_z1
  network: (( grab resource_pools.medium_z1.network ))
  stemcell: (( grab meta.stemcell ))
  env: (( grab meta.default_env ))
  cloud_properties:
    availability_zone: (( grab resource_pools.medium_z1.cloud_properties.availability_zone ))
    instance_type: (( grab resource_pools.medium_z1.cloud_properties.instance_type ))
    elbs:
      - (( grab terraform_outputs.ingestor_elb_name ))

- name: ingestor_z2
  network: (( grab resource_pools.medium_z2.network ))
  stemcell: (( grab meta.stemcell ))
  env: (( grab meta.default_env ))
  cloud_properties:
    availability_zone: (( grab resource_pools.medium_z2.cloud_properties.availability_zone ))
    instance_type: (( grab resource_pools.medium_z2.cloud_properties.instance_type ))
    elbs:
      - (( grab terraform_outputs.ingestor_elb_name ))

disk_pools:
- name: elasticsearch_master
  disk_size: 102400
  cloud_properties:
    type: gp2

- name: elasticsearch_data
  disk_size: 102400
  cloud_properties:
    type: gp2

- name: queue
  disk_size: 102400
  cloud_properties:
    type: gp2

- name: cluster_monitor
  disk_size: 102400
  cloud_properties:
    type: gp2

jobs:
- name: ingestor_z1
  release: logsearch
  templates:
  - {name: ingestor_syslog, release: logsearch}
  - {name: ingestor_relp, release: logsearch}
  resource_pool: ingestor_z1
  instances: 1
  networks:
  - name: cf1
    default: [gateway, dns]
    static_ips: (( static_ips(2) ))
  update: (( grab properties.update ))
  properties:
    redis:
      host: (( grab jobs.queue_z1.networks.cf1.static_ips.[0] ))

- name: ingestor_z2
  release: logsearch
  templates:
  - {name: ingestor_syslog, release: logsearch}
  - {name: ingestor_relp, release: logsearch}
  resource_pool: ingestor_z2
  instances: 1
  networks:
  - name: cf2
    default: [gateway, dns]
    static_ips: (( static_ips(2) ))
  update: (( grab properties.update ))
  properties:
    redis:
      host: (( grab jobs.queue_z2.networks.cf2.static_ips.[0] ))

- name: queue_z1
  release: logsearch
  templates:
  - {name: queue, release: logsearch}
  resource_pool: small_z1
  instances: 1
  networks:
  - name: cf1
    static_ips: (( static_ips(3) ))
  persistent_disk_pool: queue
  update: (( grab properties.update ))

- name: queue_z2
  release: logsearch
  templates:
  - {name: queue, release: logsearch}
  resource_pool: small_z2
  instances: 1
  networks:
  - name: cf2
    static_ips: (( static_ips(3) ))
  persistent_disk_pool: queue
  update: (( grab properties.update ))

- name: parser_z1
  release: logsearch
  templates:
  - {name: parser, release: logsearch}
  resource_pool: medium_z1
  instances: 1
  networks:
  - name: cf1
    static_ips: (( static_ips(4) ))
  update: (( grab properties.update ))
  properties:
    redis:
      host: (( grab jobs.queue_z1.networks.cf1.static_ips.[0] ))
    logstash: (( grab properties.parser_logstash ))

- name: parser_z2
  release: logsearch
  templates:
  - {name: parser, release: logsearch}
  resource_pool: medium_z2
  instances: 1
  networks:
  - name: cf2
    static_ips: (( static_ips(4) ))
  update: (( grab properties.update ))
  properties:
    redis:
      host: (( grab jobs.queue_z2.networks.cf2.static_ips.[0] ))
    logstash: (( grab properties.parser_logstash ))

- name: elasticsearch_master_z1
  release: logsearch
  templates:
  - {name: elasticsearch, release: logsearch}
  resource_pool: medium_z1
  instances: 1
  networks:
  - name: cf1
    static_ips: (( static_ips(0) ))
  persistent_disk_pool: elasticsearch_master
  properties:
    elasticsearch:
      node:
        allow_master: true
        allow_data: true
      discovery:
        minimum_master_nodes: 2
      master_hosts: (( grab properties.elasticsearch.master_hosts ))
  update: (( grab properties.update ))

- name: elasticsearch_master_z2
  release: logsearch
  templates:
  - {name: elasticsearch, release: logsearch}
  resource_pool: medium_z2
  instances: 1
  networks:
  - name: cf2
    static_ips: (( static_ips(0) ))
  persistent_disk_pool: elasticsearch_master
  properties:
    elasticsearch:
      node:
        allow_master: true
        allow_data: true
      discovery:
        minimum_master_nodes: 2
      master_hosts: (( grab properties.elasticsearch.master_hosts ))
  update: (( grab properties.update ))

- name: elasticsearch_master_z3
  release: logsearch
  templates:
  - {name: elasticsearch, release: logsearch}
  resource_pool: medium_z3
  instances: 1
  networks:
  - name: cf3
    static_ips: (( static_ips(0) ))
  persistent_disk_pool: elasticsearch_master
  properties:
    elasticsearch:
      node:
        allow_master: true
        allow_data: true
      discovery:
        minimum_master_nodes: 2
      master_hosts: (( grab properties.elasticsearch.master_hosts ))
  update: (( grab properties.update ))

- name: maintenance_z1
  instances: 1
  release: logsearch
  templates:
  - {name: elasticsearch_config, release: logsearch}
  - {name: curator, release: logsearch}
  resource_pool: small_z1
  networks:
  - name: cf1
  update: (( grab properties.update ))
  
- name: maintenance_z2
  instances: 1
  release: logsearch
  templates:
  - {name: elasticsearch_config, release: logsearch}
  - {name: curator, release: logsearch}
  resource_pool: small_z2
  networks:
  - name: cf2
  update: (( grab properties.update ))

- name: kibana
  release: logsearch
  templates:
  - {name: kibana, release: logsearch}
  resource_pool: small_z1
  instances: 1
  networks:
  - name: cf1
  update: (( grab properties.update ))

properties:
  syslog_daemon_config:
    address: (( grab terraform_outputs.ingestor_elb_dns_name ))
    port: 2514
    transport: relp
  parser_logstash:
    output:
      elasticsearch:
        data_hosts: (( grab properties.elasticsearch.master_hosts ))
  curator:
    elasticsearch_host: (( grab jobs.elasticsearch_master_z1.networks.cf1.static_ips.[0] ))
  elasticsearch:
    master_hosts: (( grab jobs.elasticsearch_master_z1.networks.cf1.static_ips jobs.elasticsearch_master_z2.networks.cf2.static_ips jobs.elasticsearch_master_z3.networks.cf3.static_ips ))
    cluster_name: logsearch
  kibana:
    elasticsearch: (( concat jobs.elasticsearch_master_z1.networks.cf1.static_ips.[0] ":9200" ))
  elasticsearch_config:
    elasticsearch:
      host: (( grab jobs.elasticsearch_master_z1.networks.cf1.static_ips.[0] ))
    templates:
      - index_template: /var/vcap/packages/logsearch-config/default-mappings.json
  logsearch:
    metrics:
      enabled: false
    logs:
      server: (( concat terraform_outputs.ingestor_elb_dns_name ":5514" ))
  update:
    serial: false
    canaries: 1
    max_in_flight: 1
