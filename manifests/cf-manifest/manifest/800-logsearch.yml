releases:
- name: logsearch
  url: https://bosh.io/d/github.com/logsearch/logsearch-boshrelease?v=203.0.0
  version: 203.0.0
  sha1: 4872c3d89fb2587d844dabbc93b124fb43b720d8
- name: logsearch-for-cloudfoundry
  version: 0.1.3
  url: https://s3-eu-west-1.amazonaws.com/gds-paas-build-releases/logsearch-for-cloudfoundry-0.1.3.tgz
  sha1: 5b7618c22224dfe7c1948dfad009aff1cdf661c4
jobs:
- (( append ))
- name: queue
  release: logsearch
  azs: [z1, z2]
  templates:
  - name: queue
    release: logsearch
  - name: datadog-logsearch-queue
    release: datadog-for-cloudfoundry
  vm_type: small
  stemcell: logsearch
  instances: 2
  networks:
  - name: cf
    static_ips:
      - 10.0.16.13
      - 10.0.17.13
  persistent_disk_type: queue

- name: parser_z1
  release: logsearch
  azs: [z1]
  templates:
  - name: parser
    release: logsearch
  - name: logsearch-for-cloudfoundry-filters
    release: logsearch-for-cloudfoundry
  vm_type: parser
  stemcell: logsearch
  instances: 1
  networks:
  - name: cf
    static_ips:
      - 10.0.16.14
  properties:
    redis:
      host: (( grab jobs.queue.networks.cf.static_ips.[0] ))
    logstash: (( grab properties.parser_logstash ))

- name: parser_z2
  release: logsearch
  azs: [z2]
  templates:
  - name: parser
    release: logsearch
  - name: logsearch-for-cloudfoundry-filters
    release: logsearch-for-cloudfoundry
  vm_type: parser
  stemcell: logsearch
  instances: 1
  networks:
  - name: cf
    static_ips:
      - 10.0.17.14
  properties:
    redis:
      host: (( grab jobs.queue.networks.cf.static_ips.[1] ))
    logstash: (( grab properties.parser_logstash ))

- name: elasticsearch_master
  release: logsearch
  azs: [z1, z2, z3]
  templates:
  - name: elasticsearch
    release: logsearch
  vm_type: elasticsearch_master
  stemcell: logsearch
  instances: 3
  networks:
  - name: cf
    static_ips:
      - 10.0.16.10
      - 10.0.17.10
      - 10.0.18.10
  persistent_disk_type: elasticsearch_master
  properties:
    elasticsearch:
      node:
        allow_master: true
        allow_data: true
      discovery:
        minimum_master_nodes: 2
      master_hosts: (( grab properties.elasticsearch.master_hosts ))

- name: maintenance
  instances: 1
  release: logsearch
  azs: [z1, z2]
  templates:
  - name: elasticsearch_config
    release: logsearch
  - name: curator
    release: logsearch
  - name: logsearch-for-cloudfoundry-filters
    release: logsearch-for-cloudfoundry
  vm_type: small
  stemcell: logsearch
  networks:
  - name: cf
  properties:
    elasticsearch_config:
      templates:
      - index_template: /var/vcap/packages/logsearch-for-cloudfoundry-filters/logs-template.json

- name: kibana
  release: logsearch
  azs: [z1, z2]
  templates:
  - name: kibana
    release: logsearch
  - name: haproxy
    release: logsearch
  vm_type: kibana
  stemcell: logsearch
  instances: 1
  networks:
  - name: cf

- name: ingestor_z1
  release: logsearch
  azs: [z1]
  templates:
  - name: ingestor_syslog
    release: logsearch
  vm_type: ingestor
  stemcell: logsearch
  instances: 1
  networks:
  - name: cf
    default: [gateway, dns]
    static_ips:
      - 10.0.16.12
  properties:
    redis:
      host: (( grab jobs.queue.networks.cf.static_ips.[0] ))
  update:
    serial: true

- name: ingestor_z2
  release: logsearch
  azs: [z2]
  templates:
  - name: ingestor_syslog
    release: logsearch
  vm_type: ingestor
  stemcell: logsearch
  instances: 1
  networks:
  - name: cf
    default: [gateway, dns]
    static_ips:
      - 10.0.17.12
  properties:
    redis:
      host: (( grab jobs.queue.networks.cf.static_ips.[1] ))
  update:
    serial: true

properties:
  syslog_daemon_config:
    enable: false
  parser_logstash:
    output:
      elasticsearch:
        data_hosts: (( grab properties.elasticsearch.master_hosts ))
  logstash_parser:
    filters:
      - logstash: /var/vcap/packages/logsearch-for-cloudfoundry-filters/logstash-filters-default.conf
      - custom-filters: /var/vcap/jobs/logsearch-for-cloudfoundry-filters/config/logstash-filters-custom.conf
    custom_filters: |
      if [@source][component] == "gorouter" {
        mutate { replace => { "type" => "gorouter" } }
        grok {
          match => {
            "@message" =>
              '%{HOSTNAME:[gorouter][host]} - \[%{TIMESTAMP_ISO8601:[gorouter][timestamp]}\] "%{WORD:[gorouter][method]} %{URIPATHPARAM:[gorouter][request]} %{NOTSPACE:[gorouter][httpversion]}" %{BASE10NUM:[gorouter][status]} %{BASE10NUM:[gorouter][bytesreceived]} %{BASE10NUM:[gorouter][bytessent]} %{QUOTEDSTRING:[gorouter][referer]} %{QUOTEDSTRING:[gorouter][useragent]} %{QUOTEDSTRING:[gorouter][clientaddr]} %{QUOTEDSTRING:[gorouter][upstreamaddr]} %{GREEDYDATA:routerkeys}'
            }
          tag_on_failure => ["fail/cloudfoundry/gorouter/grok"]
          add_tag => ["gorouter"]
        }
        kv {
          source => "router_keys"
          target => "[gorouter][header]"
          value_split => ":"
          remove_field => "router_keys"
        }
      }
      date {
        match => [ "[gorouter][timestamp]", "ISO8601" ]
        target => "@timestamp"
      }
      mutate {
        remove_field => [ "[gorouter][timestamp]" ]
      }
      if [@source][component] == "vcap_nginx_access" {
        grok {
          match => {
            "@message" =>
            '%{IPORHOST:[nginx][clientip]} - \[%{HTTPDATE:[nginx][timestamp]}\] "%{WORD:[nginx][verb]} %{URIPATHPARAM:[nginx][request]} HTTP/%{NUMBER:[nginx][httpversion]}" %{NUMBER:[nginx][response]} (?:%{NUMBER:[nginx][bytes]}|-) (?:"(?:%{URI:[nginx][referrer]}|-)"|%{QS:[nginx][referrer]}) %{QS:[nginx][agent]} %{DATA:[nginx][x_forwarded_for]} vcap_request_id:%{UUID:[nginx][vcap_request_id]} response_time:%{NUMBER:[nginx][response_time]}'
            }
        }
      }
      date {
        match => [ "[nginx][timestamp]", "dd/MMMM/yyyy:HH:mm:ss Z", "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601" ]
        target => "@timestamp"
      }
      mutate {
        remove_field => [ "[nginx][timestamp]" ]
      }

      # Remove unnecessary or empty fields
      mutate {
        remove_field => [
          "syslog5424_ver",
          "syslog_msgid",
          "syslog_procid",
          "syslog_sd_id",
          "syslog_sd_params",
          "[@source][director]"
        ]
      }

  curator:
    purge_logs:
      retention_period: 30
    elasticsearch:
      host: (( grab terraform_outputs.logsearch_elastic_master_elb_dns_name ))
  elasticsearch:
    master_hosts: (( grab jobs.elasticsearch_master.networks.cf.static_ips[0] jobs.elasticsearch_master.networks.cf.static_ips[1] jobs.elasticsearch_master.networks.cf.static_ips[2] ))
    cluster_name: logsearch
  kibana:
    elasticsearch:
      host: (( grab terraform_outputs.logsearch_elastic_master_elb_dns_name ))
      port: 9200
  haproxy:
    kibana:
      auth:
        username: admin
        password: (( grab secrets.kibana_admin_password ))
      backend_servers: ["localhost"]
      backend_port: 5601
      inbound_port: 5602
  elasticsearch_config:
    elasticsearch:
      host: (( grab terraform_outputs.logsearch_elastic_master_elb_dns_name ))
    templates:
      - index_template: /var/vcap/packages/logsearch-config/default-mappings.json
